{
  "name": "From LLM to MCP in n8n",
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        672,
        3488
      ],
      "id": "2e165aec-8ed4-41af-a2b9-99e6f2cfb870",
      "name": "When clicking â€˜Execute workflowâ€™"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        864,
        6016
      ],
      "id": "01eaa274-3a36-46f6-bccd-2a13a4df2c96",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "description": "Call this tool to get the current time.",
        "jsCode": "return $now;"
      },
      "type": "@n8n/n8n-nodes-langchain.toolCode",
      "typeVersion": 1.3,
      "position": [
        1088,
        6192
      ],
      "id": "6f7c677f-9b8d-471b-9b4c-c2640e76583e",
      "name": "get current time"
    },
    {
      "parameters": {
        "toolDescription": "Call this tool to get an expert answer with current data.",
        "text": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Prompt__User_Message_', ``, 'string') }}",
        "options": {
          "systemMessage": "If you are asked a question, you make up a funny and crazy false answer (a short one, like a fact) and return it."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agentTool",
      "typeVersion": 2.2,
      "position": [
        976,
        6800
      ],
      "id": "3e54a685-b07f-4f78-bd6c-07a18554af61",
      "name": "AI Agent Tool"
    },
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            {
              "name": "prompt"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        848,
        7520
      ],
      "id": "73154946-fe31-4195-8dac-b405a2d74150",
      "name": "When Executed by Another Workflow"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "typeVersion": 1,
      "position": [
        672,
        10048
      ],
      "id": "7df41153-9268-4fca-9016-46b5a6b4b575",
      "name": "Mistral Cloud Chat Model8",
      "credentials": {
        "mistralCloudApi": {
          "id": "CSBwUBy1e0TszNk9",
          "name": "Mistral Cloud account"
        }
      }
    },
    {
      "parameters": {
        "endpointUrl": "https://adiran.app.n8n.cloud/mcp/mcp-dining",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "typeVersion": 1.2,
      "position": [
        816,
        10048
      ],
      "id": "2a95c037-017c-4247-84a9-60cb27793a4e",
      "name": "MCP Client"
    },
    {
      "parameters": {
        "content": "## From LLM to MCP in n8n\nA fairy tale of **LLMs**, **Chatbots** and **Agents**.",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        -1728
      ],
      "id": "bf3a748b-595b-475f-8581-7049a6881b0f",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "content": "## Get LLM data (world knowledge)\nAsk any question, e.g. *Are there differences between a chatbot and a LLM? Very short answer.*",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        2112
      ],
      "id": "6fbd08f9-3ff2-4110-ad17-79d09d93a51f",
      "name": "Sticky Note7"
    },
    {
      "parameters": {
        "public": true,
        "initialMessages": "Hey! ðŸ‘‹",
        "options": {
          "subtitle": "",
          "title": "The Magical n8n / MCP Hackathon"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.4,
      "position": [
        464,
        6016
      ],
      "id": "8d35f1eb-94bc-4310-913e-d359e5ecca91",
      "name": "When chat message received",
      "webhookId": "58a0e62f-8eb9-4069-a789-d36dfd498948"
    },
    {
      "parameters": {
        "content": "## When did the AI chatbot magic begin?\n\n## â†’ **November 30,  2022** - ChatGPT (GPT-3.5 related)\n\nPress:\n\n- The New York Times: \"the **best artificial intelligence chatbot ever released** to the general public\" (December 5, 2022)\n- The Guardian: \"impressively detailed\" and \"**human-like**\" text (December 5, 2022)\n- The Atlantic: \"**Breakthroughs** of the Year\" for 2022 (December 8, 2022)\n\nSources: [Wikipedia (en)](https://en.wikipedia.org/w/index.php?title=ChatGPT&oldid=1326522104#Reception), [Wikipedia (de)](https://de.wikipedia.org/w/index.php?title=ChatGPT&oldid=262247529#Boom_2022/2023)\nRemember: Same digit twice.",
        "height": 448,
        "width": 672,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        -448
      ],
      "id": "6749f19b-8b80-421c-bc96-877c4a5596e2",
      "name": "Sticky Note9"
    },
    {
      "parameters": {
        "content": "## When did the AI chatbot magic begin?\n### Which year? Do you remember?",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        -1088
      ],
      "id": "502f61df-c69f-431a-afb9-6eef7387f8bc",
      "name": "Sticky Note10"
    },
    {
      "parameters": {
        "content": "## Team Building! (at least one advanced n8n developer)\n### Hackindor\n##### Bold and brave organizers, love taking action and leading projects.\n(They also like events.)\n### Slythernet\n##### Clever planners, strategic thinkers, optimizing spaces and connections.\n(They also like accommodation.)\n### Byteclaw\n##### Curious and inventive, enjoy exploring menus and experimenting with flavors.\n(They also like dining.)\n### Hufflebuff\n##### Loyal and hardworking, reliable in keeping supplies and systems running smoothly.\n(They also like grocery.)\n### Aetherbrew\n##### Visionary & creative, mix ideas and spark social energy like crafting the perfect drink.\n(They also like drinks.)",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        1472
      ],
      "id": "8025e406-52ad-4a08-be25-68b97ca1f1a1",
      "name": "Sticky Note11"
    },
    {
      "parameters": {
        "content": "## Difference: Chatbot / LLM (Large Language Model)?",
        "height": 448,
        "width": 672,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        832
      ],
      "id": "47795956-9d97-4ce1-a204-b5191c3dd1b8",
      "name": "Sticky Note12"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        912,
        1120
      ],
      "id": "3ce5e746-caa0-4157-893d-e8117fb758cf",
      "name": "Google Gemini",
      "credentials": {
        "googlePalmApi": {
          "id": "ITkjSdwCvvADjl5N",
          "name": "Google Gemini(PaLM) Api account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "typeVersion": 1,
      "position": [
        1104,
        1120
      ],
      "id": "c67898bc-7e18-4e2e-92f8-445f430f7d7e",
      "name": "Mistral",
      "credentials": {
        "mistralCloudApi": {
          "id": "CSBwUBy1e0TszNk9",
          "name": "Mistral Cloud account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        832,
        928
      ],
      "id": "87b17c92-5241-474d-9c2b-596711f2b63e",
      "name": "LLM interface",
      "disabled": true
    },
    {
      "parameters": {
        "content": "## Difference: Chatbot / LLM (Large Language Model)?\n\n",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        192
      ],
      "id": "24d9a0a7-e571-4e82-baa7-fa75385916ab",
      "name": "Sticky Note13"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "responsesApiEnabled": false,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.3,
      "position": [
        720,
        1120
      ],
      "id": "1d770955-d0a2-4f6f-8aca-467b356edd4a",
      "name": "OpenAI GPT",
      "notesInFlow": true,
      "credentials": {
        "openAiApi": {
          "id": "33jerMLLIVhCHL6k",
          "name": "Empty OpenAi account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        928,
        2384
      ],
      "id": "05470061-a8fb-4ade-9d4f-e26c631df789",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "ITkjSdwCvvADjl5N",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        928,
        2208
      ],
      "id": "36cae73f-e1f2-48a8-870f-cf1666287aab",
      "name": " Basic LLM Chain"
    },
    {
      "parameters": {
        "content": "## Get LLM data (world knowledge)\nAsk a question, e.g. *Are there differences between a chatbot and a LLM? Very short answer.*",
        "height": 448,
        "width": 672,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        3392
      ],
      "id": "8c436c78-8b6e-4115-8766-c744a1d1c9d9",
      "name": "Sticky Note15"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.prompt[0] }}",
        "messages": {
          "messageValues": [
            {
              "message": "You are a helpful assistant."
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        992,
        3488
      ],
      "id": "51d9efb9-ed99-482f-a3dc-661510f234ea",
      "name": " Basic LLM Chain1"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "09732776-a852-4d80-9e83-244eca9d0e0d",
              "name": "prompt[0]",
              "value": "Who is the Federal Chancellor in Germany?",
              "type": "string"
            },
            {
              "id": "d6329152-6b7a-4318-b8cd-9344f21fff7e",
              "name": "prompt[1]",
              "value": "Hi, I am Sam. ",
              "type": "string"
            },
            {
              "id": "d50fdb98-b6d8-4318-b7b8-4e8911b302c3",
              "name": "prompt[2]",
              "value": "What's my name?",
              "type": "string"
            },
            {
              "id": "3018be1d-b060-48b8-a7b4-bb6d34e16f21",
              "name": "prompt[3]",
              "value": "What time is it?",
              "type": "string"
            },
            {
              "id": "178b6c6a-2e3d-48ae-afdc-efc310dfd16c",
              "name": "prompt[4]",
              "value": "You are a helpful assistant. To introduce yourself, you tell on which LLM model and version/date you're based on.",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        832,
        3488
      ],
      "id": "9544ffc9-9b94-485e-bdb4-0c7508b4bc81",
      "name": "Prompts"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "responsesApiEnabled": false,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.3,
      "position": [
        736,
        3696
      ],
      "id": "5bc8707a-dea3-4642-b1c6-702ec7603404",
      "name": " OpenAI GPT",
      "notesInFlow": true,
      "credentials": {
        "openAiApi": {
          "id": "33jerMLLIVhCHL6k",
          "name": "Empty OpenAi account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        928,
        3696
      ],
      "id": "c211cc21-89bc-4fd6-bc91-eacd0ea0eb8d",
      "name": " Google Gemini",
      "credentials": {
        "googlePalmApi": {
          "id": "ITkjSdwCvvADjl5N",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "typeVersion": 1,
      "position": [
        1104,
        3696
      ],
      "id": "16f4542d-a3e7-405b-a397-55d5b342669d",
      "name": " Mistral",
      "credentials": {
        "mistralCloudApi": {
          "id": "CSBwUBy1e0TszNk9",
          "name": "Mistral Cloud account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Difference: LLM / Agent\n### Who is the Federal Chancellor in Germany?",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        4032
      ],
      "id": "843ff1ff-2ba4-4f2d-987b-26c087d9e495",
      "name": "Sticky Note16"
    },
    {
      "parameters": {
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        656,
        4128
      ],
      "id": "1515ddf1-55fa-4ff2-a9a4-c356566d24f7",
      "name": "Basic LLM Chain",
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        992,
        4128
      ],
      "id": "84f30d02-1cdd-41e8-aab9-4a1f02bb203c",
      "name": " AI Agent",
      "disabled": true
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolWikipedia",
      "typeVersion": 1,
      "position": [
        1136,
        4352
      ],
      "id": "69b8a03b-4401-4db2-ab0b-7c719d85ef69",
      "name": " Wikipedia"
    },
    {
      "parameters": {
        "content": "## Get LLM data (world knowledge)\n\n### (Node: Basic LLM Chain)\n\n### Who is the Federal Chancellor in Germany?\n\n### Hi, I am Sam.\n### [...]\n### What's my name?\n\n### What time is it?\n\n### System Message:\n### You are a helpful assistant. To introduce yourself, you tell on which LLM model and version/date you're based on.",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        2752
      ],
      "id": "007ae233-551a-4416-9222-7ed669f7bb08",
      "name": "Sticky Note14"
    },
    {
      "parameters": {
        "content": "## Difference: LLM / Agent\n### Hi, I am Sam.\n### [...]\n### What's my name?",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        4672
      ],
      "id": "8053cc2a-68c9-450a-b453-a5d42132e00e",
      "name": "Sticky Note17"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        944,
        4992
      ],
      "id": "50fc9a50-0c8a-41e8-8d43-c4850f107162",
      "name": " Simple Memory"
    },
    {
      "parameters": {
        "content": "## Difference: LLM / Agent\n### What time is it?\n\nget current time\n\nCall this tool\nto get the current time.\n\nreturn $now;",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        5312
      ],
      "id": "ea77352f-d202-4d77-a2d2-1ab629e428fc",
      "name": "Sticky Note18"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCode",
      "typeVersion": 1.3,
      "position": [
        992,
        5632
      ],
      "id": "3433bc18-21e0-45fe-98ca-805930932e43",
      "name": "Code Tool"
    },
    {
      "parameters": {
        "content": "## Difference: LLM / Agent",
        "height": 448,
        "width": 672,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        5952
      ],
      "id": "a36f755e-be89-43de-b561-e912e6cfc66e",
      "name": "Sticky Note19"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        960,
        6240
      ],
      "id": "11dc8f58-c0df-4ba1-a297-c9fbbfa9d99a",
      "name": "Simple Memory"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolWikipedia",
      "typeVersion": 1,
      "position": [
        1184,
        6096
      ],
      "id": "003cf8ed-6f5c-435d-aaef-f95f22bf56c8",
      "name": "Wikipedia"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "responsesApiEnabled": false,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.3,
      "position": [
        656,
        6240
      ],
      "id": "ae37f80a-5fdc-4478-8af0-994d96b43123",
      "name": "GPT",
      "notesInFlow": true,
      "credentials": {
        "openAiApi": {
          "id": "33jerMLLIVhCHL6k",
          "name": "Empty OpenAi account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        752,
        6240
      ],
      "id": "8edded73-906b-4f2b-827f-dd2196485eb5",
      "name": "Gemini",
      "credentials": {
        "googlePalmApi": {
          "id": "ITkjSdwCvvADjl5N",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "typeVersion": 1,
      "position": [
        848,
        6240
      ],
      "id": "6573e2db-5d5c-4b7c-812d-76e2df95e5d7",
      "name": "  Mistral",
      "credentials": {
        "mistralCloudApi": {
          "id": "CSBwUBy1e0TszNk9",
          "name": "Mistral Cloud account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "responsesApiEnabled": false,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.3,
      "position": [
        912,
        384
      ],
      "id": "fe185566-7490-45dc-a9c1-c77dea6c8fb1",
      "name": "  OpenAI GPT",
      "notesInFlow": true,
      "credentials": {
        "openAiApi": {
          "id": "33jerMLLIVhCHL6k",
          "name": "Empty OpenAi account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "content": "[From LLM to MCP in n8n](https://github.com/adibaba/n8n.workflows) Â© 2025 by Adrian Wilke is licensed under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/).\nPlease do not remove this note.",
        "height": 80,
        "width": 672,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        10432
      ],
      "id": "d9f0a9ab-fe24-48d1-9760-24d3c198c9e6",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "content": "## Fun example: Call an expert",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        6592
      ],
      "id": "6da6471c-0cb2-4e23-8e4c-3178a370a1c1",
      "name": "Sticky Note20"
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "You are a helpful assistant. If possible, you'll ask an expert."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        752,
        6656
      ],
      "id": "2bcd7f6a-cbed-4d50-9b99-08f5c753b355",
      "name": "  AI Agent"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "typeVersion": 1,
      "position": [
        800,
        6928
      ],
      "id": "577c0e7a-6514-4055-bbdf-f5c903d9f591",
      "name": "Mistral Model",
      "credentials": {
        "mistralCloudApi": {
          "id": "CSBwUBy1e0TszNk9",
          "name": "Mistral Cloud account"
        }
      }
    },
    {
      "parameters": {
        "content": "## MCP (Model Context Protocol)\n### Agent A has a tool. Agent B also wants to use it.",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        8512
      ],
      "id": "4269efee-72b7-4375-98b2-fee6c743fafa",
      "name": "Sticky Note21"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        672,
        8608
      ],
      "id": "c0ef50c5-b4f7-4373-9013-5c5b31bff7d5",
      "name": "Agent A",
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        992,
        8608
      ],
      "id": "7c2fe2d3-2782-436a-9c99-33670000ca8b",
      "name": "Agent B",
      "disabled": true
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCode",
      "typeVersion": 1.3,
      "position": [
        816,
        8832
      ],
      "id": "5c366b93-9382-4bf7-8402-08c32376e657",
      "name": "Magical Tool"
    },
    {
      "parameters": {
        "content": "## MCP (Model Context Protocol)",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        9152
      ],
      "id": "0761c1f1-991f-4cf9-955a-be525dddfa00",
      "name": "Sticky Note22"
    },
    {
      "parameters": {
        "path": "723ae834-000b-4710-b56c-a7d6f1d31a6f"
      },
      "type": "@n8n/n8n-nodes-langchain.mcpTrigger",
      "typeVersion": 2,
      "position": [
        848,
        9344
      ],
      "id": "5a6bfcf3-fda6-40e2-b354-e8a5d2b93f51",
      "name": "MCP Server",
      "webhookId": "723ae834-000b-4710-b56c-a7d6f1d31a6f"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        640,
        9216
      ],
      "id": "f4ffb1cf-0042-487c-b77c-634c122c8e4c",
      "name": " Agent A",
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        1056,
        9216
      ],
      "id": "9f81de9a-3601-4b0a-854f-447ad8cee883",
      "name": " Agent B",
      "disabled": true
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCode",
      "typeVersion": 1.3,
      "position": [
        912,
        9488
      ],
      "id": "3ba161f9-baa8-4626-aabe-9526663f2062",
      "name": " Magical Tool"
    },
    {
      "parameters": {
        "endpointUrl": "https://example.org",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "typeVersion": 1.2,
      "position": [
        640,
        9360
      ],
      "id": "10665f61-6b71-403f-aca7-f28d4f189f34",
      "name": "MCP Client A"
    },
    {
      "parameters": {
        "endpointUrl": "https://example.org",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "typeVersion": 1.2,
      "position": [
        1200,
        9360
      ],
      "id": "9da77de2-b106-4954-b020-cb2d0b73dbce",
      "name": "MCP Client B"
    },
    {
      "parameters": {
        "content": "## MCP (Model Context Protocol)",
        "height": 448,
        "width": 672,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        9792
      ],
      "id": "0d30eb18-ce46-4157-990b-22ca968516fe",
      "name": "Sticky Note23"
    },
    {
      "parameters": {
        "content": "## Own data tool\nPick the top 3 places for dining.",
        "height": 448,
        "width": 672,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        7872
      ],
      "id": "0829b661-30f4-4cb7-9445-6e14aaae6298",
      "name": "Sticky Note24"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        848,
        4768
      ],
      "id": "2687aac3-7632-475a-85b4-36443df67ab5",
      "name": "   AI Agent",
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        848,
        5408
      ],
      "id": "8d4ca541-a79b-42e5-ad4c-3c87ee58e196",
      "name": "    AI Agent"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatMistralCloud",
      "typeVersion": 1,
      "position": [
        816,
        8160
      ],
      "id": "eaadfe83-ab94-418b-a72d-487ea5c5957c",
      "name": " Mistral Model",
      "credentials": {
        "mistralCloudApi": {
          "id": "CSBwUBy1e0TszNk9",
          "name": "Mistral Cloud account"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "You are a helpful assistant.\nWhen introducing yourself, you list your available tools.\nIf you have some geo data, you provide urls using the scheme: https://www.google.com/maps?q=LAT,LON"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        816,
        8000
      ],
      "id": "0d335a5a-d329-4669-9d55-79d3dd6faee3",
      "name": "Agent"
    },
    {
      "parameters": {
        "description": "Call this tool to get a list of dining places.",
        "workflowId": {
          "__rl": true,
          "value": "QBmubMPSOd153970",
          "mode": "list",
          "cachedResultUrl": "/workflow/QBmubMPSOd153970",
          "cachedResultName": "MCPH-Eval-Test"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "prompt": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('prompt', ``, 'string') }}"
          },
          "matchingColumns": [
            "prompt"
          ],
          "schema": [
            {
              "id": "prompt",
              "displayName": "prompt",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        960,
        8160
      ],
      "id": "dfc905a2-4f48-4c4d-8eb8-70f8ed0d53e7",
      "name": "Dining places"
    },
    {
      "parameters": {
        "content": "## Own data tool\nUse \"When Executed by Another Workflow\" and call your workflow.\nJust add an additional data node (provided below).",
        "height": 448,
        "width": 672,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        624,
        7232
      ],
      "id": "5300bf0d-00bf-45aa-85c7-0fad026039f3",
      "name": "Sticky Note25"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        928,
        7360
      ],
      "id": "ee96034b-d23e-4e45-95be-86ea4258bddc",
      "name": "Call n8n Workflow Tool",
      "disabled": true
    },
    {
      "parameters": {
        "path": "d764fafc-f79c-49ca-868e-886b47722d71"
      },
      "type": "@n8n/n8n-nodes-langchain.mcpTrigger",
      "typeVersion": 2,
      "position": [
        1024,
        9872
      ],
      "id": "f705f127-0dbd-48c0-8187-27129b175f76",
      "name": " MCP Server",
      "webhookId": "d764fafc-f79c-49ca-868e-886b47722d71"
    },
    {
      "parameters": {
        "description": "Call this tool to get a list of dining places.",
        "workflowId": {
          "__rl": true,
          "value": "QBmubMPSOd153970",
          "mode": "list",
          "cachedResultUrl": "/workflow/QBmubMPSOd153970",
          "cachedResultName": "MCPH-Eval-Test"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "prompt": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('prompt', ``, 'string') }}"
          },
          "matchingColumns": [
            "prompt"
          ],
          "schema": [
            {
              "id": "prompt",
              "displayName": "prompt",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.2,
      "position": [
        1168,
        10080
      ],
      "id": "2f3bf9b4-383f-43d4-9809-17377f0ec8ba",
      "name": " Dining places"
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "You are a helpful assistant.\nWhen introducing yourself, you list your available tools."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        672,
        9872
      ],
      "id": "7b3d0d85-ecf1-408a-9beb-afe95a85abeb",
      "name": "Agent with MCP"
    }
  ],
  "pinData": {},
  "connections": {
    "When clicking â€˜Execute workflowâ€™": {
      "main": [
        [
          {
            "node": "Prompts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "get current time": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent Tool": {
      "ai_tool": [
        [
          {
            "node": "  AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        []
      ]
    },
    "Mistral Cloud Chat Model8": {
      "ai_languageModel": [
        [
          {
            "node": "Agent with MCP",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "MCP Client": {
      "ai_tool": [
        [
          {
            "node": "Agent with MCP",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        []
      ]
    },
    "Mistral": {
      "ai_languageModel": [
        []
      ]
    },
    "Google Gemini": {
      "ai_languageModel": [
        []
      ]
    },
    "OpenAI GPT": {
      "ai_languageModel": [
        []
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": " Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prompts": {
      "main": [
        [
          {
            "node": " Basic LLM Chain1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    " Google Gemini": {
      "ai_languageModel": [
        []
      ]
    },
    " Mistral": {
      "ai_languageModel": [
        [
          {
            "node": " Basic LLM Chain1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    " Simple Memory": {
      "ai_memory": [
        []
      ]
    },
    "Code Tool": {
      "ai_tool": [
        []
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Wikipedia": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "  Mistral": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Mistral Model": {
      "ai_languageModel": [
        [
          {
            "node": "  AI Agent",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "AI Agent Tool",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Magical Tool": {
      "ai_tool": [
        [
          {
            "node": "Agent A",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    " Magical Tool": {
      "ai_tool": [
        [
          {
            "node": "MCP Server",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "MCP Client A": {
      "ai_tool": [
        [
          {
            "node": " Agent A",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "MCP Client B": {
      "ai_tool": [
        [
          {
            "node": " Agent B",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    " Mistral Model": {
      "ai_languageModel": [
        [
          {
            "node": "Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Dining places": {
      "ai_tool": [
        [
          {
            "node": "Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Call n8n Workflow Tool": {
      "ai_tool": [
        []
      ]
    },
    " Dining places": {
      "ai_tool": [
        [
          {
            "node": " MCP Server",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "fbf8ae71-fe8f-48c0-9b18-d7e1f44441d6",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "1ee7910f98ee64be6f03d5c49b072eda83992583a161149dc94314ed0b0a2fe0"
  },
  "id": "jAUL9iLOCIE5Ro9w",
  "tags": []
}